Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,-0.12892433,622.5,0.25,0.25,1.0
20000,1.4189284,0.0021844492,791.0,0.08333333333333333,0.08333333333333333,1.0
30000,1.418899,-0.384828,725.1428571428571,0.07142857142857142,0.07142857142857142,1.0
40000,1.418894,-0.2682242,591.1764705882352,0.29411764705882354,0.29411764705882354,1.0
50000,1.4188899,-0.41158822,692.6923076923077,0.07692307692307693,0.07692307692307693,1.0
60000,1.4188993,-0.14197566,707.1333333333333,0.06666666666666667,0.06666666666666667,1.0
70000,1.4189278,-0.107435755,753.3571428571429,0.14285714285714285,0.14285714285714285,1.0
80000,1.4189456,-0.18495108,558.1666666666666,0.16666666666666666,0.16666666666666666,1.0
90000,1.4189397,-0.06021336,751.9166666666666,0.0,0.0,1.0
100000,1.4189323,0.06745989,567.1578947368421,0.21052631578947367,0.21052631578947367,1.0
